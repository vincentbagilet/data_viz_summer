{
  "hash": "15b73f8708ff4a01526c8de104a90fb9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Causal Exaggeration and Calibration\"\nsubtitle: \"Causal identification strategies are essential to make causal claims. They can however also come at a cost and create bias (exaggeration). We discuss this trade-off in this session.\"\npublished-title: \"Date\"\ndate: \"2024-10-02\"\nself-contained: true\nengine: knitr\n---\n\n\n::: callout-tip\n## Objective\n\nAfter this session, you should understand the importance of the variation used to identify the effect of interest and be able to calibrate your simulation.\n:::\n\n## Summary\n\nThis session focuses on **causal exaggeration**^[This session builds on [a working paper I am working on](https://vincentbagilet.github.io/causal_exaggeration/).]. Causal identification strategies only use part of the variation, the exogeneous part. This reduces precision and statistical power and can create exaggeration, leading significant and published estimates to exaggerate the true effect, even when the estimator is unbiased in the traditional sense. The variation used for identification is the key driver of the resulting trade-off between confounding and exaggeration. \n\nTo illustrate this, I built fake-data simulations that I calibarated based on actual studies. This lead us to discuss why and how **calibrating** simulations.\n\n### Session Outline\n\n1.  Homework: Treatment Effect Heterogeneity\n2.  Summary from last week\n3.  Causal exaggeration\n4.  Calibrating simulations\n\n## Materials\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 384 512\" style=\"height:1em;width:0.75em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm72 208c-13.3 0-24 10.7-24 24V336v56c0 13.3 10.7 24 24 24s24-10.7 24-24V360h44c42 0 76-34 76-76s-34-76-76-76H136zm68 104H160V256h44c15.5 0 28 12.5 28 28s-12.5 28-28 28z\"/></svg>`{=html} [Open slides](../../slides/lecture_4/slides_4_causal_exagg.html)\n\n\n::: {.cell}\n<iframe src=\"../../slides/lecture_4/slides_4_causal_exagg.html\" width=\"100%\" height=\"400px\" data-external=\"1\"></iframe>\n:::\n\n\n## Exercise\n\nBefore Friday October 11, 7pm, please submit [here](https://forms.gle/eTr4ZdbZtiHYZ7ko7) a `html` document, generated with Quarto, implementing the analysis described in [this document](ex/ex_2_calibration.qmd).\n\n## Specific resources for this lecture\n\n- This class is based on [one of my working papers](https://vincentbagilet.github.io/causal_exaggeration/). You can find more details there.\n\n### Comparison IV and OLS\n\n- [Young (2022)](https://www.sciencedirect.com/science/article/pii/S001429212200054X#sec0010) replicate 30 papers from the economics literature (AEA journals). Find that:\n    - 75% of the 2SLS 95% CI contain the corresponding OLS point estimates (67.3% of main results)\n    - IV estimates often larger (in absolute terms) or opposite sign than OLS: “greater than 0.5 times the absolute value of the OLS point estimate in .73 of headline regressions”\n    - 2SLS estimates usually do not provide meaningful information regarding the extent to which OLS are biased\n- [Lal et al. (2024)](https://www.cambridge.org/core/journals/political-analysis/article/how-much-should-we-trust-instrumental-variable-estimates-in-political-science-practical-advice-based-on-67-replicated-studies/70A232CA0CD55FE8B97E93543CDD6361#article) replicate 67 papers from the political science literature. Find that:\n    - For 97% of designs studied 2SLS > OLS (34% at least 5 times larger)\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}