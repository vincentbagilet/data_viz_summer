{
  "hash": "4fa2135f4f5868620b8866c78d13d0a3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Power and Exaggeration\"\nsubtitle: \"AFOs and water pollution\"\npublished-title: \"Date\"\ndate: \"2024-09-24\"\nself-contained: true\nengine: knitr\nhtml-math-method: mathml\n---\n\n::: {.cell}\n\n:::\n\n\nIn this document, we will explore the characteristics of significant estimates in under powered studies. For this, let's implement a simple simulation of the impact of Animal Feeding Operations (AFOs) on water pollution.\n\nThere are two potential sources of pollution: manure lagoons or sprayfields. We want to know whether the pollution observed downstream comes from lagoons or sprayfields. For now, we assume that both sources of pollution come from excess rainfall.\n\nFor now, assume that the level of pollution in every water quality station depends only on the pollution due to one lagoon and one sprayfield (in addition to inobserved factors). We are interested in the level of pollution at the water station level and in particular at the impact of having a lagoon overfol and sprayfield. Assume that it is determined by the effect of lagoons, \n\n\n\n\n<!-- ```{r} -->\n<!-- n_lagoons <- 50 -->\n<!-- n_fields <- 50 -->\n<!-- pollution <- 4 -->\n<!-- ``` -->\n\n<!-- Identification strategy: consider AFOs whose confinement site and sprayfields are in different watersheds -->\n\n<!-- Given our sample sizes, are we sufficiently powered to detect effects of reasonable sizes? -->\n\n<!-- Let's assume that -->\n\n<!-- The potential polluter = a mix of a point-source and non-point source; specifically: animal feeding operations (AFOs), which store the source of the pollution (manure) first at the location of the confinement site, then spread it onto sprayfields. Both have a priori the potential to pollute surface waters (at location #1, which is \\~ point source: e.g. from lagoon failures; at location #2, which is \\~ non-point source: from runoff from oversaturated soils). We want to know whether the pollution observed downstream comes from either/both, as policy implications would differ. Identification strategy: consider AFOs whose confinement site and sprayfields are in different watersheds; following a high rainfall event, do we detect an increase in pollution downstream? Statistical challenge: given our sample sizes of AFOs and outcome data, are we sufficiently powered to detect effects of reasonable sizes? -->\n\n<!-- ### Characteristics of significant estimates -->\n\n<!-- Let's reproduce the previous graph but conditioning on significance, in order to visualize potential differences between significant and non-significant estimates. -->\n\n<!-- ```{r plot_signif} -->\n<!-- #| code-fold: true -->\n\n<!-- res |>  -->\n<!--   arrange(sim_id) |>  -->\n<!--   slice(1:30) |>  -->\n<!--   mutate(signif = ifelse(p.value < 0.05, \"Significant\", \"Non-significant\")) |>  -->\n<!--   ggplot(aes(x = sim_id, y = estimate, color = signif)) +  -->\n<!--   geom_point() +  -->\n<!--   geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) + -->\n<!--   geom_hline(yintercept = beta_0) + -->\n<!--   geom_hline(yintercept = 0, linetype = \"solid\", color = \"black\") + -->\n<!--   labs( -->\n<!--     title = \"Estimates of the ATE\", -->\n<!--     subtitle = paste(\"Conditional on significance at the 5% level\"), -->\n<!--     x = \"Simulation id\",  -->\n<!--     y = \"Estimate\", -->\n<!--     color = NULL -->\n<!--   )  -->\n\n<!-- res |>  -->\n<!--   mutate(signif = ifelse(p.value < 0.05, \"Significant\", \"Non-significant\")) |>  -->\n<!--   ggplot(aes(x = estimate, fill = signif, color = signif)) +  -->\n<!--   geom_dotplot(alpha = 0.8) +  -->\n<!--   labs( -->\n<!--     title = paste(\"Distribution of\", n_iter, \"estimates of the ATE\"), -->\n<!--     subtitle = paste(\"Conditional on significance at the 5% level\"), -->\n<!--     x = \"Estimate\", -->\n<!--     y = NULL, -->\n<!--     caption = \"Each dot represents one estimate\", -->\n<!--     fill = NULL, -->\n<!--     color = NULL -->\n<!--   ) + -->\n<!--   theme(panel.grid.major.y = element_blank(), axis.text.y = element_blank()) -->\n<!-- ``` -->\n\n<!-- Significant estimates are larger than non-significant ones. Basically, to be significant, estimates have to be far enough from zero: at least 1.96 standard errors away from 0. They therefore have to be \"large enough\" to be significant. -->\n\n<!-- Note that on average, statistically significant estimates over estimate the true effect: this is called **exaggeration** or **type-M** error. -->\n\n<!-- We will now explore the impact of some parameters on statistical power and the output of our analysis. This will allow us to answer the question of interest: which sample size and proportion of treated students should we choose for our experiment in order to have an adequate statistical power? -->\n\n<!-- ## Parameters affecting the statistical power -->\n\n<!-- ### Statistical power, effect size, precision -->\n\n<!-- Before looking at the specifics of our analysis, let's quickly review some basic statistical power theory. In general, for unbiased estimators, the larger the true underlying effect (*ie*, the further away from zero the true effect is), the larger the power. To illustrate this, we can plot the distribution of several unbiased estimators that have the same characteristics[^1] except for the value of the true effect of their estimand: -->\n\n<!-- [^1]: Normally distributed with a standard error of 0.5. -->\n\n<!-- ```{r power_effect_size, fig.asp=1.2} -->\n<!-- #| code-fold: true -->\n\n<!-- crossing(se = 0.5, mean = seq(0.2, 2, by = 0.4)) |>  -->\n<!--   crossing(id = 1:10000) |>  -->\n<!--   group_by(mean, se) |>  -->\n<!--   mutate(estimate = rnorm(10000, mean, se)) |>  -->\n<!--   mutate( -->\n<!--     signif = ifelse( -->\n<!--       estimate > qnorm(0.975)*se,  -->\n<!--       \"Significant\",  -->\n<!--       \"Non-significant\" -->\n<!--     ) -->\n<!--   ) |>  -->\n<!--   ggplot(aes(x = estimate, fill = signif)) + -->\n<!--   geom_histogram(bins = 100) +  -->\n<!--   geom_vline(aes(xintercept = mean), color = \"white\") +  -->\n<!--   geom_vline(xintercept = 0, linetype = \"solid\", color = \"black\") +  -->\n<!--   facet_wrap(~ paste(\"True effect =\", mean), ncol = 1) +  -->\n<!--   labs( -->\n<!--     title = \"Distribution of 10,000 significant estimates depending on the true effect\", -->\n<!--     subtitle = \"The larger the true effect, the larger the power\", -->\n<!--     x = \"Estimate\", -->\n<!--     y = \"Count\", -->\n<!--     fill = NULL,  -->\n<!--     caption = \"The vertical dashed white line represents the true effect\" -->\n<!--   ) -->\n<!-- ``` -->\n\n<!-- Significant estimates are estimates that are larger than 1.96 times the standard error. Since this threshold does not depend on the effect size, it is the same for all the estimators we consider here (about 0.98). Now, since the estimators are unbiased, they are centered on the true effect. Thus, the larger the true effect, the further to the right each distribution and therefore the more estimates are above the fixed 1.96 S.E. threshold and the larger the power. -->\n\n<!-- Similarly, if we now hold the true effect constant, we can plot the distribution of several estimators with varying precision, *ie*, varying standard errors. -->\n\n<!-- ```{r power_se, fig.asp=1.2} -->\n<!-- #| code-fold: true -->\n\n<!-- crossing(mean = 1, se = seq(0.2, 1, by = 0.2)) |>  -->\n<!--   crossing(id = 1:10000) |>  -->\n<!--   group_by(mean, se) |>  -->\n<!--   mutate(estimate = rnorm(10000, mean, se)) |>  -->\n<!--   mutate( -->\n<!--     signif = ifelse( -->\n<!--       estimate > qnorm(0.975)*se,  -->\n<!--       \"Significant\",  -->\n<!--       \"Non-significant\" -->\n<!--     ) -->\n<!--   ) |>  -->\n<!--   ggplot(aes(x = estimate, fill = signif)) + -->\n<!--   geom_histogram(bins = 100) +  -->\n<!--   geom_vline(aes(xintercept = mean), color = \"white\") +  -->\n<!--   geom_vline(xintercept = 0, linetype = \"solid\", color = \"black\") +  -->\n<!--   facet_wrap(~ paste(\"S.E. =\", se), ncol = 1) +  -->\n<!--   labs( -->\n<!--     title = \"Distribution of 10,000 significant estimates depending on the S.E.\", -->\n<!--     subtitle = \"The more precise the estimator, the larger the power\", -->\n<!--     x = \"Estimate\", -->\n<!--     y = \"Count\", -->\n<!--     fill = NULL,  -->\n<!--     caption = \"The vertical dashed white line represents the true effect\" -->\n<!--   ) -->\n<!-- ``` -->\n\nHere, the distribution remains centered on the same value. However, the significance threshold, located $1.96\\times S.E.$ from 0, of course varies with the standard error. The less precise the estimator, the further away from 0 the threshold is. When the relative precision is very limited, significant estimates end up located in the tail of the distribution. Since the distribution is centered on the true effect (the estimator is unbiased so centered on the true effect), significant estimates overestimate the true effect.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}